{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b824097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from spmfunctions.misc_tools import detector_status, phase_status, overlap_status, comb_gyr_det\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e23eae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self):\n",
    "        self.cap = None\n",
    "        self.fps = 0\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.shapes = []\n",
    "        self.current_shape = []\n",
    "        self.mode = 'loop'\n",
    "        self.color = (0, 255, 0)\n",
    "        self.input_val = 1\n",
    "        self.phase = 1\n",
    "\n",
    "    def read_video(self, video_path):\n",
    "        \"\"\"Read video and get properties\"\"\"\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        return self.cap, self.fps, self.width, self.height\n",
    "\n",
    "    def draw_shape(self, img, shape):\n",
    "        \"\"\"Draw a shape on image\"\"\"\n",
    "        if shape['type'] == 'loop':\n",
    "            pts = np.array(shape['points'], dtype=np.int32)\n",
    "            cv2.polylines(img, [pts], isClosed=True, color=shape['color'], thickness=2)\n",
    "        elif shape['type'] == 'stopbar':\n",
    "            pt1, pt2 = shape['points']\n",
    "            cv2.line(img, pt1, pt2, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"Handle mouse events for drawing\"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.current_shape.append((x, y))\n",
    "            if len(self.current_shape) == 4 and self.mode == 'loop':\n",
    "                # Compute 4th corner for rotated rectangle\n",
    "                self.shapes.append({\n",
    "                    'type': 'loop',\n",
    "                    'points': list(self.current_shape),\n",
    "                    'color': self.color,\n",
    "                    'input': self.input_val\n",
    "                })\n",
    "                self.current_shape = []\n",
    "            elif len(self.current_shape) == 2 and self.mode == 'stopbar':\n",
    "                self.shapes.append({\n",
    "                    'type': 'stopbar',\n",
    "                    'points': list(self.current_shape),\n",
    "                    'phase': self.phase\n",
    "                })\n",
    "                self.current_shape = []\n",
    "\n",
    "    def draw_shapes_interface(self):\n",
    "        \"\"\"Interactive interface for drawing shapes with Tkinter input dialogs\"\"\"\n",
    "\n",
    "        if not self.cap:\n",
    "            raise ValueError(\"Video not loaded\")\n",
    "        \n",
    "        ret, first_frame = self.cap.read()\n",
    "        if not ret:\n",
    "            raise ValueError(\"Cannot read first frame\")\n",
    "        \n",
    "        # Reset to beginning\n",
    "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        \n",
    "        image = first_frame.copy()\n",
    "        cv2.namedWindow(\"Draw Shapes\")\n",
    "        cv2.setMouseCallback(\"Draw Shapes\", self.mouse_callback)\n",
    "\n",
    "        # Tkinter root for dialogs\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "\n",
    "        # Create a small always-on-top Tkinter window for instructions\n",
    "        instruction_window = tk.Toplevel()\n",
    "        instruction_window.title(\"Draw Shapes Instructions\")\n",
    "        instruction_window.attributes('-topmost', True)\n",
    "        instruction_window.resizable(False, False)\n",
    "        instruction_text = (\n",
    "            \"Instructions:\\n\"\n",
    "            \"- Press 'l' to switch to loop mode (4 points)\\n\"\n",
    "            \"- Press 's' to switch to stop bar mode (2 points)\\n\"\n",
    "            \"- Press 'c' to change color (for loops)\\n\"\n",
    "            \"- Press 'i' to set input value (for loops)\\n\"\n",
    "            \"- Press 'p' to set phase value (for stop bars)\\n\"\n",
    "            \"- Press 'u' to undo last action\\n\"\n",
    "            \"- Click to draw shapes\\n\"\n",
    "            \"- Press 'q' when finished\"\n",
    "        )\n",
    "        label = tk.Label(instruction_window, text=instruction_text, justify='left', padx=10, pady=10)\n",
    "        label.pack()\n",
    "        # Position the window at the top right corner\n",
    "        instruction_window.update_idletasks()\n",
    "        screen_width = instruction_window.winfo_screenwidth()\n",
    "        window_width = instruction_window.winfo_width()\n",
    "        instruction_window.geometry(f\"+{screen_width - window_width - 40}+40\")\n",
    "\n",
    "        colors = {\n",
    "            'Green': (0, 255, 0),\n",
    "            'Blue': (255, 0, 0),\n",
    "            'Red': (0, 0, 255),\n",
    "            'Yellow': (255, 255, 0),\n",
    "            'Magenta': (255, 0, 255),\n",
    "            'Cyan': (0, 255, 255),\n",
    "            'Black': (0, 0, 0)\n",
    "        }\n",
    "        color_index = 0\n",
    "\n",
    "        while True:\n",
    "            img_copy = image.copy()\n",
    "            \n",
    "            # Draw existing shapes\n",
    "            for shape in self.shapes:\n",
    "                self.draw_shape(img_copy, shape)\n",
    "            \n",
    "            # Draw current shape being created\n",
    "            if len(self.current_shape) > 0:\n",
    "                for pt in self.current_shape:\n",
    "                    cv2.circle(img_copy, pt, 5, (0, 0, 0), -1)\n",
    "                if len(self.current_shape) == 2:\n",
    "                    cv2.line(img_copy, self.current_shape[0], self.current_shape[1], (0, 0, 0), 2)\n",
    "                elif len(self.current_shape) == 3:\n",
    "                    cv2.line(img_copy, self.current_shape[1], self.current_shape[2], (0, 0, 0), 2)\n",
    "                elif len(self.current_shape) == 4:\n",
    "                    pts = np.array(self.current_shape, dtype=np.int32)\n",
    "                    cv2.polylines(img_copy, [pts], isClosed=True, color=(0, 0, 0), thickness=1)\n",
    "\n",
    "            # Display current mode and values\n",
    "            mode_text = f\"Mode: {self.mode}\"\n",
    "            if self.mode == 'loop':\n",
    "                color_name = next((name for name, rgb in colors.items() if rgb == self.color), str(self.color))\n",
    "                mode_text += f\" | Color: {color_name} | Input: {self.input_val}\"\n",
    "            else:\n",
    "                mode_text += f\" | Phase: {self.phase}\"\n",
    "            cv2.putText(img_copy, mode_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"Draw Shapes\", img_copy)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('l'):\n",
    "                self.mode = 'loop'\n",
    "            elif key == ord('s'):\n",
    "                self.mode = 'stopbar'\n",
    "            elif key == ord('c'):\n",
    "                color_names = list(colors.keys())\n",
    "                color_index = (color_index + 1) % len(color_names)\n",
    "                color_name = color_names[color_index]\n",
    "                self.color = colors[color_name]\n",
    "            elif key == ord('i'):\n",
    "                inp = simpledialog.askinteger(\"Input Value\", \"Enter input value (1-64):\", minvalue=1, maxvalue=64)\n",
    "                if inp is not None:\n",
    "                    self.input_val = inp\n",
    "            elif key == ord('p'):\n",
    "                phase_input = simpledialog.askstring(\"Phase Value\", \"Enter phase value (1-16 or A-P):\")\n",
    "                if phase_input:\n",
    "                    phase_input = phase_input.strip().upper()\n",
    "                    if phase_input.isdigit():\n",
    "                        phase = int(phase_input)\n",
    "                        if 1 <= phase <= 16:\n",
    "                            self.phase = phase\n",
    "                        else:\n",
    "                            messagebox.showerror(\"Phase\", \"Phase must be between 1-16\")\n",
    "                    elif len(phase_input) == 1 and 'A' <= phase_input <= 'P':\n",
    "                        self.phase = f\"OL{phase_input}\"\n",
    "                    else:\n",
    "                        messagebox.showerror(\"Phase\", \"Phase must be between 1-16 or A-P\")\n",
    "            elif key == ord('u'):  # Undo last action\n",
    "                if self.current_shape:\n",
    "                    self.current_shape.pop()\n",
    "                    print(\"Undone: Removed last point.\")\n",
    "                elif self.shapes:\n",
    "                    removed_shape = self.shapes.pop()\n",
    "                    shape_type = removed_shape['type'].title()\n",
    "                    print(f\"Undone: Removed last {shape_type} shape.\")\n",
    "                else:\n",
    "                    print(\"Nothing to undo.\")\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        root.destroy()\n",
    "        return self.shapes\n",
    "\n",
    "    def save_shapes_to_csv(self, filename):\n",
    "        \"\"\"Save shapes to CSV file\"\"\"\n",
    "        with open(filename, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['type', 'points', 'color', 'input', 'phase', 'video_width', 'video_height'])\n",
    "            for shape in self.shapes:\n",
    "                points_str = ';'.join([f\"{pt[0]},{pt[1]}\" for pt in shape['points']])\n",
    "                color_str = f\"{shape.get('color', (0,0,0))[0]},{shape.get('color', (0,0,0))[1]},{shape.get('color', (0,0,0))[2]}\"\n",
    "                writer.writerow([\n",
    "                    shape['type'],\n",
    "                    points_str,\n",
    "                    color_str,\n",
    "                    shape.get('input', ''),\n",
    "                    shape.get('phase', ''),\n",
    "                    self.width,\n",
    "                    self.height\n",
    "                ])\n",
    "\n",
    "    def load_shapes_from_csv(self, filename):\n",
    "        \"\"\"Load shapes from CSV file\"\"\"\n",
    "        shapes = []\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r') as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                for row in reader:\n",
    "                    points = []\n",
    "                    for pt_str in row['points'].split(';'):\n",
    "                        x, y = map(int, pt_str.split(','))\n",
    "                        points.append((x, y))\n",
    "                    \n",
    "                    color = tuple(map(int, row['color'].split(','))) if row['color'] else (0, 255, 0)\n",
    "                    \n",
    "                    shape = {\n",
    "                        'type': row['type'],\n",
    "                        'points': points,\n",
    "                        'color': color,\n",
    "                        'input': int(row['input']) if row['input'] else None,\n",
    "                        'phase': row['phase'] if row['phase'] else None\n",
    "                    }\n",
    "                    shapes.append(shape)\n",
    "        self.shapes = shapes\n",
    "        return shapes\n",
    "\n",
    "    def load_and_process_data(self, pickle_path, start_time_str, end_time_str, time_step=0.1):\n",
    "        \"\"\"Load and process data from pickle file with datetime filtering\"\"\"\n",
    "        df = pd.read_pickle(pickle_path)\n",
    "        \n",
    "        # Convert start and end times to datetime\n",
    "        start_dt = pd.to_datetime(start_time_str)\n",
    "        end_dt = pd.to_datetime(end_time_str)\n",
    "        df_start = start_dt - pd.Timedelta(hours=1)  # 1 hour before start_dt\n",
    "        df_end = end_dt + pd.Timedelta(hours=1)      # 1 hour after end_dt\n",
    "        \n",
    "        # Filter data to relevant time range\n",
    "        df = df[(df['TS_start'] >= df_start) & (df['TS_start'] <= df_end)]\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"Warning: No data found in the specified time range\")\n",
    "            return df\n",
    "        \n",
    "        # Get relevant phases and detectors from shapes\n",
    "        relevant_phases = list(set([s['phase'] for s in self.shapes if s['type'] == 'stopbar' and s['phase'] is not None and \"OL\" not in str(s['phase'])]))\n",
    "        \n",
    "        # Map overlap names like \"OLA\", \"OLB\", etc. to numbers: \"OLA\"->1, \"OLB\"->2, ...\n",
    "        overlap_map = {f\"OL{chr(ord('A') + i)}\": i + 1 for i in range(26)}\n",
    "        relevant_overlaps = []\n",
    "        for s in self.shapes:\n",
    "            if s['type'] == 'stopbar' and s['phase'] is not None and \"OL\" in str(s['phase']):\n",
    "                phase_str = str(s['phase'])\n",
    "                mapped_val = overlap_map.get(phase_str)\n",
    "                if mapped_val is not None:\n",
    "                    relevant_overlaps.append(mapped_val)\n",
    "        relevant_overlaps = list(set(relevant_overlaps))\n",
    "        \n",
    "        relevant_detectors = list(set([s['input'] for s in self.shapes if s['type'] == 'loop' and s['input'] is not None]))\n",
    "\n",
    "\n",
    "        df = comb_gyr_det(df)\n",
    "        df = detector_status(df, relevant_detectors)\n",
    "        df = phase_status(df, relevant_phases)\n",
    "        df = overlap_status(df, relevant_overlaps)\n",
    "        \n",
    "        # Select relevant columns\n",
    "        cols_to_keep = ['TS_start']\n",
    "        for ph in relevant_phases:\n",
    "            col_name = f'Ph {ph} Status'\n",
    "            if col_name in df.columns:\n",
    "                cols_to_keep.append(col_name)\n",
    "        for ol in relevant_overlaps:\n",
    "            col_name = f'OL{chr(ord(\"A\") + ol - 1)} Status' if ol <= 26 else f'OL{ol} Status'\n",
    "            if col_name in df.columns:\n",
    "                cols_to_keep.append(col_name)\n",
    "        for det in relevant_detectors:\n",
    "            col_name = f'Det {det} Status'\n",
    "            if col_name in df.columns:\n",
    "                cols_to_keep.append(col_name)\n",
    "\n",
    "        \n",
    "        df = df[cols_to_keep]\n",
    "        df.drop_duplicates(subset=['TS_start'], inplace=True, keep='last')\n",
    "        df.sort_values('TS_start', inplace=True)\n",
    "\n",
    "        # Expand timestamps\n",
    "        if not df.empty:\n",
    "            expanded_times = pd.date_range(start=start_dt, end=end_dt, freq=f'{int(time_step*1000)}ms')\n",
    "            expanded_df = pd.DataFrame({'TS_start': expanded_times})\n",
    "\n",
    "            # Merge and forward-fill\n",
    "            merged_df = pd.merge_asof(expanded_df, df, on='TS_start', direction='forward')\n",
    "            return merged_df\n",
    "        \n",
    "        df.to_csv('expanded_data.csv', index=False)\n",
    "        return df\n",
    "\n",
    "    def extract_frames_at_intervals(self, start_dt, end_dt, interval=0.1):\n",
    "        \"\"\"Extract frames at specified datetime intervals\"\"\"\n",
    "        frames = []\n",
    "        timestamps = []\n",
    "\n",
    "        # Convert datetime to seconds from video start\n",
    "        video_start_time = 0.0  # Assuming video starts at 0 seconds\n",
    "        \n",
    "        current_dt = start_dt\n",
    "        while current_dt <= end_dt:\n",
    "            # Calculate time in seconds from video start\n",
    "            time_diff = (current_dt - start_dt).total_seconds()\n",
    "            current_time = video_start_time + time_diff\n",
    "            \n",
    "            frame_idx = int(current_time * self.fps)\n",
    "            self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                frames.append(frame.copy())\n",
    "                timestamps.append(current_dt)\n",
    "            current_dt += pd.Timedelta(seconds=interval)\n",
    "\n",
    "        return frames, timestamps\n",
    "\n",
    "    def overlay_shapes(self, frame, row_data):\n",
    "        \"\"\"Overlay shapes on frame based on data\"\"\"\n",
    "        for shape in self.shapes:\n",
    "            if shape['type'] == 'loop' and shape['input'] is not None:\n",
    "                det_col = f\"Det {shape['input']} Status\"\n",
    "                status = row_data.get(det_col, 'na') if det_col in row_data else 'na'\n",
    "\n",
    "                if pd.isna(status) or status == 'na':\n",
    "                    outline_color = (0,0,0)\n",
    "                    fill_color = None\n",
    "                    alpha = 0\n",
    "                elif status == 'Off':\n",
    "                    outline_color = shape['color']\n",
    "                    fill_color = None\n",
    "                    alpha = 0\n",
    "                elif status == 'On':\n",
    "                    outline_color = (255, 255, 255)\n",
    "                    fill_color = shape['color']\n",
    "                    alpha = 0.2\n",
    "\n",
    "                pts = np.array(shape['points'], dtype=np.int32)\n",
    "                if alpha > 0:\n",
    "                    overlay = frame.copy()\n",
    "                    cv2.fillPoly(overlay, [pts], fill_color)\n",
    "                    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "                cv2.polylines(frame, [pts], isClosed=True, color=outline_color, thickness=1)\n",
    "\n",
    "            elif shape['type'] == 'stopbar' and shape['phase'] is not None:\n",
    "                # Determine if phase is overlap (e.g., 'OLA', 'OLB', ...) or integer\n",
    "                phase_val = shape['phase']\n",
    "                # Check if phase is integer-like (int or string of digits)\n",
    "                if isinstance(phase_val, int) or (isinstance(phase_val, str) and phase_val.isdigit()):\n",
    "                    ph_col = f\"Ph {phase_val} Status\"\n",
    "                else:\n",
    "                    ph_col = f\"{phase_val} Status\"\n",
    "                status = row_data.get(ph_col, 'na') if ph_col in row_data else 'na'\n",
    "                color_map = {'R': (0, 0, 255), 'Y': (0, 255, 255), 'G': (0, 255, 0), 'Rc': (0, 0, 255), 'na': (128, 128, 128)}\n",
    "                color = color_map.get(status, (0, 0, 0))  # Default to black if status not recognized\n",
    "                pt1, pt2 = shape['points']\n",
    "                cv2.line(frame, pt1, pt2, color, thickness=3)\n",
    "\n",
    "    def write_video(self, frames, output_path, fps):\n",
    "        \"\"\"Write frames to output video\"\"\"\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (self.width, self.height))\n",
    "        for frame in frames:\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "\n",
    "    def process_video(self, video_path, pickle_path, output_path, shape_csv, time_step=0.1, \n",
    "                     start_time_str=None, end_time_str=None):\n",
    "        \"\"\"Main processing function with datetime support\"\"\"\n",
    "        # Read video\n",
    "        self.read_video(video_path)\n",
    "        \n",
    "        # Load or create shapes\n",
    "        if os.path.exists(shape_csv):\n",
    "            self.load_shapes_from_csv(shape_csv)\n",
    "            print(f\"Loaded {len(self.shapes)} shapes from {shape_csv}\")\n",
    "        else:\n",
    "            print(\"No shape file found. Starting drawing interface...\")\n",
    "            self.draw_shapes_interface()\n",
    "            self.save_shapes_to_csv(shape_csv)\n",
    "            print(f\"Saved {len(self.shapes)} shapes to {shape_csv}\")\n",
    "        \n",
    "        # Validate datetime inputs\n",
    "        if not start_time_str or not end_time_str:\n",
    "            raise ValueError(\"Start and end times are required\")\n",
    "        \n",
    "        try:\n",
    "            start_dt = pd.to_datetime(start_time_str)\n",
    "            end_dt = pd.to_datetime(end_time_str)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Invalid datetime format: {e}\")\n",
    "        \n",
    "        # Load and process data\n",
    "        df = self.load_and_process_data(pickle_path, start_time_str, end_time_str, time_step)\n",
    "        if df.empty:\n",
    "            print(\"No data to process in the specified time range\")\n",
    "            return\n",
    "\n",
    "        # Extract frames\n",
    "        frames, timestamps = self.extract_frames_at_intervals(start_dt, end_dt, time_step)\n",
    "        print(f\"Extracted {len(frames)} frames\")\n",
    "\n",
    "        # Process frames with overlays\n",
    "        for i, (frame, ts) in enumerate(zip(frames, timestamps)):\n",
    "            if not df.empty:\n",
    "                # Find closest data row\n",
    "                closest_idx = (df['TS_start'] - ts).abs().argmin()\n",
    "                row_data = df.iloc[closest_idx]\n",
    "                self.overlay_shapes(frame, row_data)\n",
    "            \n",
    "            # Add timestamp to frame\n",
    "            timestamp_str = ts.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-5]  # Show up to tenth of second\n",
    "            cv2.putText(frame, timestamp_str, (10, self.height - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        # Write output video\n",
    "        output_fps = 1.0 / time_step\n",
    "        self.write_video(frames, output_path, output_fps)\n",
    "        print(f\"Output video saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9779c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path, pickle_path, output_path, shape_csv, start_time_str, end_time_str, time_step=0.1):\n",
    "    \"\"\"Main function\"\"\"\n",
    "    processor = VideoProcessor()\n",
    "   \n",
    "    if not start_time_str or not end_time_str:\n",
    "        print(\"Start and end datetime are required!\")\n",
    "        return\n",
    "\n",
    "    # Process video\n",
    "    try:\n",
    "        processor.process_video(video_path, pickle_path, output_path, shape_csv, \n",
    "                              time_step, start_time_str, end_time_str)\n",
    "        print(\"Processing completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No shape file found. Starting drawing interface...\n",
      "Saved 2 shapes to ../banks-lowman3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rhansen\\OneDrive - Idaho Transportation Department\\Documents\\Python\\SPMs\\Notebooks\\spmfunctions\\misc_tools.py:215: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_comb.ffill(inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m end_time_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2025-07-28 16:28:33.0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m time_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 11\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(video_path, pickle_path, output_path, shape_csv, start_time_str, end_time_str, time_step)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Process video\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[50], line 406\u001b[0m, in \u001b[0;36mVideoProcessor.process_video\u001b[1;34m(self, video_path, pickle_path, output_path, shape_csv, time_step, start_time_str, end_time_str)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Extract frames\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m frames, timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_frames_at_intervals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_dt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_dt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(frames)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m frames\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# Process frames with overlays\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 315\u001b[0m, in \u001b[0;36mVideoProcessor.extract_frames_at_intervals\u001b[1;34m(self, start_dt, end_dt, interval)\u001b[0m\n\u001b[0;32m    312\u001b[0m current_time \u001b[38;5;241m=\u001b[39m video_start_time \u001b[38;5;241m+\u001b[39m time_diff\n\u001b[0;32m    314\u001b[0m frame_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(current_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps)\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#video_path = input(\"Enter video path: \").strip() or \"input.mp4\"\n",
    "#pickle_path = input(\"Enter pickle data path: \").strip() or \"data.pkl\"\n",
    "#output_path = input(\"Enter output video path: \").strip() or \"output.mp4\"\n",
    "#shape_csv = input(\"Enter shape CSV path: \").strip() or \"shapes.csv\"\n",
    "#start_time_str = input(\"Enter start datetime (yyyy-mm-dd hh:mm:ss.0): \").strip()\n",
    "#end_time_str = input(\"Enter end datetime (yyyy-mm-dd hh:mm:ss.0): \").strip()\n",
    "#try:\n",
    "#    time_step = float(input(\"Enter time step (seconds, e.g., 0.1): \") or \"0.1\")\n",
    "#except ValueError:\n",
    "#    time_step = 0.1\n",
    "\n",
    "pickle_path = '../intersections/SH-55 & Banks-Lowman/Data/DataFrames/df_raw_2025_07_28_1615-2025_07_28_1630.pkl'\n",
    "output_path = '../output2025-07-28_3.mp4'\n",
    "shape_csv = '../banks-lowman3.csv'\n",
    "\n",
    "#video_path = '../vlc-record-2025-07-26-14h35m03s-rtsp___10.37.23.204_axis-media_media.amp-.mp4'\n",
    "#start_time_str = '2025-07-26 15:35:24.0'\n",
    "#end_time_str = '2025-07-26 15:37:02.0'\n",
    "\n",
    "#video_path = '../vlc-record-2025-07-26-14h38m16s-rtsp___10.37.23.204_axis-media_media.amp-.mp4'\n",
    "#start_time_str = '2025-07-26 15:38:38.0'\n",
    "#end_time_str = '2025-07-26 15:42:17.0'\n",
    "\n",
    "#video_path = '../vlc-record-2025-07-28-13h03m55s-rtsp___10.37.23.204_axis-media_media.amp-.mp4'\n",
    "#start_time_str = '2025-07-28 14:04:20.0'\n",
    "#end_time_str = '2025-07-28 14:19:17.0'\n",
    "\n",
    "#video_path = '../vlc-record-2025-07-28-13h20m03s-rtsp___10.37.23.204_axis-media_media.amp-.mp4'\n",
    "#start_time_str = '2025-07-28 14:20:34.0'\n",
    "#end_time_str = '2025-07-28 14:26:02.0'\n",
    "\n",
    "video_path = '../Recording 2025-07-28 152942.mp4'\n",
    "start_time_str = '2025-07-28 16:23:26.0'\n",
    "end_time_str = '2025-07-28 16:28:33.0'\n",
    "\n",
    "time_step=0.2\n",
    "\n",
    "main(video_path, pickle_path, output_path, shape_csv, start_time_str, end_time_str, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1477d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
